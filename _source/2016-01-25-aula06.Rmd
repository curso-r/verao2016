---
title: Aula 06 - Laboratório II
date : 2015-01-30
layout: post
comments: true
--- 

# Questões iniciais

## Sobre dplyr e tidyr

Para estas questões usaremos a base de dados flights, ela está inserida no pacote `nycflights13` por isso é necessário utilizar o comando: 

```{r}
library(nycflights13)
```

Se você não tiver o pacote instalado use o comando:

```{r, eval = F}
install.packages("nycflighs13")
```

E em seguida use o `library(nycflights13)`.

```{r}
library(dplyr)
flights %>% tbl_df
```

Com o comando `?flights` você pode ver o que significa cada uma das variáveis do banco de dados.

### filter

1. Atribua a uma tabela apenas os voos de janeiro de 2013.
2. Atribua a uma tabela apenas os voos de janeiro ou fevereiro de 2013.
3. Atribua a uma tabela apenas os vôos com distância maior do que 1000 milhas.

### select

1. Atribua a uma tabela apenas as colunas `month` e `dep_delay`.
2. Atribua a uma tabela apenas as colunas `month` e `dep_delay`, os nomes dessas colunas devem ser `mes`e `atraso`.
3. Retire da tabela as colunas `tailnum`, `origin` e `dest`

### mutate

1. Calcule as colunas `ganho_de_tempo` que é dado por `dep_delay - arr_delay` e `velocidade` dada por `distance / air_time * 60`.
2. Calcule o horário de chegada considerando as colunas `hour`, `minute` e `air_time`. A tabela deve conter duas colunas novas: `hour2` com a hora de chegada e `minute2` com o minuto de chegada.

### summarise

1. Calcule a média da distância de todos os vôos.
2. Calcule a média da distância dos vôos por mês
3. Calcule a média, mediana, primeiro quartil e terceiro quartil do tempo de viagem por mês.

### arrange

1. Ordene a base de dados pelo atraso na partida em ordem crescente.
2. Repita a questão anterior, porém na ordem decrescente.

### spread

1. Crie uma tabela em que cada linha é um dia e cada coluna é o atraso médio de partida por mês.

Resultado esperado:
```{r, echo = F}
library(tidyr)
flights %>% 
  group_by(day, month) %>% 
  dplyr::summarise(delay = mean(dep_delay, na.rm = T)) %>% 
  spread(month, delay) %>% head
```

Dica: você precisará usar `group_by`, `summarise`e `spread`. Lembre-se também do argumento `na.rm`.

2. Repita a mesma operação, mas dessa vez cada coluna será uma hora do dia.


Resultado esperado:
```{r, echo = F}
flights %>% 
  group_by(day, hour) %>% 
  dplyr::summarise(delay = mean(dep_delay, na.rm = T)) %>% 
  spread(day, delay) %>% tbl_df() %>% head
```

### gather

Considerando as tabelas criadas nas perguntas sobre o `spread`:

1. Transforme-as em um formato tidy.

Resultado esperado:
```{r, echo = F}
flights %>% 
  group_by(day, month) %>% 
  dplyr::summarise(delay = mean(dep_delay, na.rm = T)) %>% 
  spread(month, delay) %>% 
  gather(mes, delay, -day) %>% head
```


### desafios (opcional)

1. Sumarise em uma tabela qual foi a média de atraso total (`dep_delay + arr_delay`) e seu intervalo de confiança por mês, apenas considerando os vôos que atrasaram (tempos negativos não são atrasos).
Dica: o intervalo de confiança pode ser calculado por $média \pm 1,96*\sqrt{\frac{var(x)}{n}}$

2. Summarise em uma tabela quais foram os 10 destinos com mais viagens com atraso superior a 60 minutos. Considere o atraso total definido na pergunta anterior.

---

## Sobre ggplot2

Nestes exercícios você utilizará a base de dados `diamonds`, do pacote `ggplot2`.

Instalação do pacote `ggplot2`:

```{r, eval = F}
install.packages("ggplot2")
```

Para carregar o pacote `ggplot2`:

```{r}
library(ggplot2)
```

Enfim, os dados:

```{r}
head(diamonds, 10)
```

Para ver uma descrição das variáveis deste banco de dados, utilize a função `help()`:

```{r}
help(diamonds)
```


## Geral

**1.** Segundo a *Grammar of Graphics*, o que é um gráfico estatístico? Responda de forma sucinta.

**2.** Qual operador é usado para acrescentar *camadas* em um gráfico no ggplot?

### geom_point

**3.** Quais são os aspectos estéticos (*aesthetics*) exigidos (obrigatórios) da função `geom_point()`?

Dica: utilizar a função `help()`.

**4.** Faça um gráfico de dispersão do preço (*price*) pela variável quilates (*carat*). Utilize as funções `xlab()` e `ylab()` para trocar os *labels* dos eixos x e y, respectivamente.

**5.** Utilize a função `facet_grid()` ou `facet_wrap()` para fazer gráficos de dispersão do preço pela variável quilate (o mesmo gráfico do exercício 1) para cada nível da variável claridade (*clarity*).

### geom_line

**6.** Quais são os aspectos estéticos (*aesthetics*) exigidos (obrigatórios) da função `geom_line()`?

Dica: visitar a seguinte [página](http://docs.ggplot2.org/current/) e consultar o tópico `geom_line`.

**7.** Utilizando o argumento `stat = summary` e `fun.y = mean`, calcule a média do preço para cada corte, faça um gráfico desses pontos utilizando a função `geom_point()`e trace uma reta sobre esses pontos utilizando a função `geom_line()`. 

Dicas: não se esqueça de especificar o *aesthetic* `group =` dentro do `geom_line()`. Veja mais exemplos de como usar o `stat = summary` [aqui](http://docs.ggplot2.org/current/stat_summary.html).

### geom_histogram

**8.** Quais são os aspectos estéticos (*aesthetics*) exigidos (obrigatórios) da função `geom_histogram()`?

**9.** Faça um histograma da variável preço. 

**10.** Utilize a função `geom_density()` para **adicionar** ao gráfico anterior uma estimativa suavizada da densidade. Por que, neste caso, é preciso especificar o argumento `y = ` como `..density..`?


### geom_boxplot

**11.** Quais são os aspectos estéticos (*aesthetics*) exigidos (obrigatórios) da função `geom_boxplot()`?

**12.** Faça boxplots da variável preço pela variável corte (*cut*).

### geom_bar

**13.** Quais são os aspectos estéticos (*aesthetics*) exigidos (obrigatórios) da função `geom_bar()`?

**14.** Faça um gráfico de barras do número de diamantes em cada categoria da variável cor (*color*).


### Desafio (opcional)

Supondo que esses diamantes são vendidos nos EUA, siga os seguintes passos:


- Considerando que, para obter o seu lucro, um vendedor brasileiro venda um diamante (em reais) por `2.61*price*2.2`, acrescente uma coluna ao banco de dados representando o preço de venda no Brasil.

- Considere agora que, para importar um diamante diretamente dos EUA, uma transportadora cobre (em reais) `(carat*price*0.70)*2.61 + price*2.68`, já considerando o preço de compra do diamante. Adicione ao banco de dados uma coluna referente ao preço de cada diamante se importado diretamente.

- Faça um gráfico de dispersão do preço de venda no Brasil pelo preço de importação. Adicione a esse gráfico uma reta x=y para avaliar quais diamantes compensam ser importados diretamente.

- Mapeie a variável *clarity* ao gráfico acima. Quais são os tipos de claridades que, em geral, não compensam ser importadas diretamente? Faça o mesmo para a variável *color*.

*Dica*: para fazer a reta x=y, utilize a função `geom_abline()`.

# Desafios com bases de dados reais

Primeiro, instale o pacote `abjutils`. Para isso, instale primeiro o pacote `devtools`.

```{r eval=FALSE}
# verifica se o pacote devtools já está instalado e instala se não estiver
if(!require(devtools)) install.packages('devtools')

# verifica se o pacote abjutils já está instalado e instala se não estiver
# Como o pacote não está no CRAN, instalamos via github usando o comando do pacote devtools
if(!require(abjutils)) devtools::install_github('abjur/abjutils')

# OBS: O pacote abjutils já vai carregar as bibliotecas dplyr, stringr e lubridate
```


## PNUD

Vamos começar com a base de dados do PNUD do lab 1, para aquecer :)

Você pode carregar o banco de dados do PNUD rodando

```{r eval=FALSE}
data(pnud_muni , package='abjutils')
```

**1** Refaça todas as análises do laboratório 1 usando `dplyr` e `ggplot2`.

## Coalitions

Essa base de dados contém informações de países que fazem parte da Organização Mundial do Comércio (OMC, em inglês World Trade Organization - WTO). Para melhorar e facilitar o comércio internacional, muitas vezes os países que fazem parte da OMC realizam acordos, que chamamos de _coalizões_. Geralmente uma coalizão
envolve muitos países ao mesmo tempo.

```{r eval=FALSE}
data(wto_data , package='abjutils')
data(wto_dyad_sample, package='abjutils')
```

A base de dados `wto_data` contém informações básicas de cada país, como PIB, PIB _per capita_, latitude, longitude, hemisfério, identificador de regime político, etc. O código do país é dado na variável `ccode`

A base de dados `wto_dyad_sample` contém, em cada linha, uma coalizão ocorrida ou não na Organização Mundial do Comércio, entre dois países (uma "díade" ou, em inglês, _dyad_). 

Os países estão identificados pelas colunas `ccode1` e `ccode2` (analogamente à base `wto_data`). A coalizão é identificada `coalition`, que vale `1` se houve coalizão e `0` caso contrário. A coluna `ccoalition` é um identificador de qual foi a coalizão que aconteceu (Mercosul, acordos da Europa, etc).

**1** Faça um mapa com as posições geográficas dos países, com um mapa múndi no fundo.

Dica: Leia o script da aula 05.

**2**. Qual é a unidade observacional (o que identifica uma observação) na base `wto_data`?

**3**. Quantas coalizões tivemos em cada ano?

**4**. Qual é o código do país que entrou mais vezes em alguma coalizão?

**5**. Construa uma matriz de adjacências usando `dplyr` e `tidyr`. Queremos um `data.frame` `wto_adj` com número de linhas igual ao número de colunas, e o conteúdo da célula `wto_adj[i, j]` é `1` se o país da linha entra em coalizão com o país da coluna em dado ano e dada coalizão, e `0` caso contrário. Utilize a função `row.names()` para atribuir os nomes às linhas.

## CARF

A base de dados do Conselho Administrativo de Recursos Fiscais (CARF) é uma das muitas bases que geralmente temos de lidar na área de jurimetria (estatística aplicada ao direito). Trata-se de uma base de dados sobre processos tributários.

Montamos uma base de dados com todas as decisões encontradas no conselho. Nosso banco de dados tem, inicialmente, 264594 linhas e somente 9 colunas. As variáveis estão descritas abaixo:

- `id`: número sequencial único para identificar cada acórdão.
- `n_processo`: número do processo. 
- `n_decisao`: número da decisão.
- `ano`: ano em que o acórdão foi proferido (de acordo com o site do CARF).
- `tipo_recurso`: identifica se a decisão é sobre um recurso voluntário, recurso de ofício, recurso especial, etc.
- `contribuinte`: identifica o nome do contribuinte, em texto livre.
- `relator`: identifica o nome do relator, em texto livre.
- `txt_ementa`: texto completo da ementa, em texto livre. Geralmente esse texto contém informações do tributo discutido, fundamentação da decisão e decisão.
- `txt_decisao`: texto completo da decisão, em texto livre. Geralmente é uma parte da ementa, contendo apenas a parte relacionada à decisão, mas não é uma regra.

**1** Quantos processos temos na base de dados?

**2** Construa um gráfico contendo o volume de acórdãos em cada ano. Você nota algum ano com comportamento estranho?

**3** Agora retire da base os acórdãos que contêm texto da decisão e texto da ementa vazios. Refaça o gráfico e interprete.

**4** Utilizando a função `str_detect()`, crie colunas (que valem `TRUE` ou `FALSE`) na base de dados de acordo com as expressões regulares abaixo.

```{r eval=FALSE}
negar_provimento <- 'negar?(do)? (o )?provimento|negou se (o )?provimento|recurso nao provido'
dar_provimento <- 'dar?(do)? (o )?provimento|deu se (o )?provimento|recurso provido'
em_parte <- 'em parte|parcial'
diligencia <- 'diligencia'
nao_conhecer <- 'conhec'
anular <- 'nul(a|o|i)'
```

**5** Faça um gráfico de barras mostrando a quantidade de acórdãos em que foi dado provimento, negado provimento, etc. Considere somente os casos em que `tipo_recurso` é recurso voluntário.

## SABESP

Usando um _web crawler_ desenvolvido em R, fizemos o download da base de dados da SABESP. Quem tiver interesse nesses dados, acesse [aqui](https://github.com/jtrecenti/sabesp).

```{r eval=FALSE}
data(sabesp, package='abjutils')
```

**1** Descreva a base de dados.

**2** Crie um boxplot por mês, mostrando os lugares separadamente.

**3** Tente montar um gráfico parecido com esse (inclusive as cores e as labels inclinadas do eixo x). Não vale olhar o código do repositório no github!

<img src="https://raw.githubusercontent.com/jtrecenti/sabesp/master/sabesp_files/figure-html/unnamed-chunk-2-2.png"> </img>

**4** Construa uma tabela descritiva contendo a média, mediana, desvio padrão, primeiro e terceiro quartis em relação à pluviometria, agrupando por ano e por lugar.

**5** Comente sobre a crise hídrica em São Paulo com base em conhecimentos próprios e usando os dados da sabesp.
