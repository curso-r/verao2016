---
title: "Aula 03 - Laboratório"
author: "Curso R"
date: 2016-01-22
output: html_document
tags: lab
layout: post
comments: true
category: lab
---

# Questões iniciais

## Sobre dplyr e tidyr

Para estas questões usaremos a base de dados flights, ela está inserida no pacote `nycflights13` por isso é necessário utilizar o comando: 

```{r}
library(nycflights13)
```

Se você não tiver o pacote instalado use o comando:

```{r, eval = F}
install.packages("nycflighs13")
```

E em seguida use o `library(nycflights13)`.

```{r}
library(dplyr)
flights %>% tbl_df
```

Com o comando `?flights` você pode ver o que significa cada uma das variáveis do banco de dados.

### filter

1. Atribua a uma tabela apenas os voos de janeiro de 2013.
2. Atribua a uma tabela apenas os voos de janeiro ou fevereiro de 2013.
3. Atribua a uma tabela apenas os vôos com distância maior do que 1000 milhas.

### select

1. Atribua a uma tabela apenas as colunas `month` e `dep_delay`.
2. Atribua a uma tabela apenas as colunas `month` e `dep_delay`, os nomes dessas colunas devem ser `mes`e `atraso`.
3. Retire da tabela as colunas `tailnum`, `origin` e `dest`

### mutate

1. Calcule as colunas `ganho_de_tempo` que é dado por `dep_delay - arr_delay` e `velocidade` dada por `distance / air_time * 60`.
2. Calcule o horário de chegada considerando as colunas `hour`, `minute` e `air_time`. A tabela deve conter duas colunas novas: `hour2` com a hora de chegada e `minute2` com o minuto de chegada.

### summarise

1. Calcule a média da distância de todos os vôos.
2. Calcule a média da distância dos vôos por mês
3. Calcule a média, mediana, primeiro quartil e terceiro quartil do tempo de viagem por mês.

### arrange

1. Ordene a base de dados pelo atraso na partida em ordem crescente.
2. Repita a questão anterior, porém na ordem decrescente.

### spread

1. Crie uma tabela em que cada linha é um dia e cada coluna é o atraso médio de partida por mês.

Resultado esperado:
```{r, echo = F}
library(tidyr)
flights %>% 
  group_by(day, month) %>% 
  dplyr::summarise(delay = mean(dep_delay, na.rm = T)) %>% 
  spread(month, delay) %>% head
```

Dica: você precisará usar `group_by`, `summarise`e `spread`. Lembre-se também do argumento `na.rm`.

2. Repita a mesma operação, mas dessa vez cada coluna será uma hora do dia.


Resultado esperado:
```{r, echo = F}
flights %>% 
  group_by(day, hour) %>% 
  dplyr::summarise(delay = mean(dep_delay, na.rm = T)) %>% 
  spread(day, delay) %>% tbl_df() %>% head
```

### gather

Considerando as tabelas criadas nas perguntas sobre o `spread`:

1. Transforme-as em um formato tidy.

Resultado esperado:
```{r, echo = F}
flights %>% 
  group_by(day, month) %>% 
  dplyr::summarise(delay = mean(dep_delay, na.rm = T)) %>% 
  spread(month, delay) %>% 
  gather(mes, delay, -day) %>% head
```


### desafios (opcional)

1. Sumarise em uma tabela qual foi a média de atraso total (`dep_delay + arr_delay`) e seu intervalo de confiança por mês, apenas considerando os vôos que atrasaram (tempos negativos não são atrasos).
Dica: o intervalo de confiança pode ser calculado por $média \pm 1,96*\sqrt{\frac{var(x)}{n}}$

2. Summarise em uma tabela quais foram os 10 destinos com mais viagens com atraso superior a 60 minutos. Considere o atraso total definido na pergunta anterior.

# Desafios com outras bases de dados reais

## Coalitions

Essa base de dados contém informações de países que fazem parte da Organização Mundial do Comércio (OMC, em inglês World Trade Organization - WTO). Para melhorar e facilitar o comércio internacional, muitas vezes os países que fazem parte da OMC realizam acordos, que chamamos de _coalizões_. Geralmente uma coalizão
envolve muitos países ao mesmo tempo.

```{r eval=FALSE}
data(wto_data , package='abjutils')
data(wto_dyad_sample, package='abjutils')
```

A base de dados `wto_data` contém informações básicas de cada país, como PIB, PIB _per capita_, latitude, longitude, hemisfério, identificador de regime político, etc. O código do país é dado na variável `ccode`

A base de dados `wto_dyad_sample` contém, em cada linha, uma coalizão ocorrida ou não na Organização Mundial do Comércio, entre dois países (uma "díade" ou, em inglês, _dyad_). 

Os países estão identificados pelas colunas `ccode1` e `ccode2` (analogamente à base `wto_data`). A coalizão é identificada `coalition`, que vale `1` se houve coalizão e `0` caso contrário. A coluna `ccoalition` é um identificador de qual foi a coalizão que aconteceu (Mercosul, acordos da Europa, etc).

**1**. Qual é a unidade observacional (o que identifica uma observação) na base `wto_data`?

**1**. Quantas coalizões tivemos em cada ano?

**1**. Qual é o código do país que entrou mais vezes em alguma coalizão?

**1**. Construa uma matriz de adjacências usando `dplyr` e `tidyr`. Queremos um `data.frame` `wto_adj` com número de linhas igual ao número de colunas, e o conteúdo da célula `wto_adj[i, j]` é `1` se o país da linha entra em coalizão com o país da coluna em dado ano e dada coalizão, e `0` caso contrário. Utilize a função `row.names()` para atribuir os nomes às linhas.

## CARF

A base de dados do Conselho Administrativo de Recursos Fiscais (CARF) é uma das muitas bases que geralmente temos de lidar na área de jurimetria (estatística aplicada ao direito). Trata-se de uma base de dados sobre processos tributários.

Montamos uma base de dados com todas as decisões encontradas no conselho. Nosso banco de dados tem, inicialmente, 264594 linhas e somente 9 colunas. As variáveis estão descritas abaixo:

- `id`: número sequencial único para identificar cada acórdão.
- `n_processo`: número do processo. 
- `n_decisao`: número da decisão.
- `ano`: ano em que o acórdão foi proferido (de acordo com o site do CARF).
- `tipo_recurso`: identifica se a decisão é sobre um recurso voluntário, recurso de ofício, recurso especial, etc.
- `contribuinte`: identifica o nome do contribuinte, em texto livre.
- `relator`: identifica o nome do relator, em texto livre.
- `txt_ementa`: texto completo da ementa, em texto livre. Geralmente esse texto contém informações do tributo discutido, fundamentação da decisão e decisão.
- `txt_decisao`: texto completo da decisão, em texto livre. Geralmente é uma parte da ementa, contendo apenas a parte relacionada à decisão, mas não é uma regra.

**1** Quantos processos temos na base de dados?

**1** Construa uma tabela contendo o volume de acórdãos em cada ano. Você nota algum ano com comportamento estranho?

**1** Agora retire da base os acórdãos que contêm texto da decisão e texto da ementa vazios. Refaça a tabela e interprete.

**1** Utilizando a função `str_detect()`, crie colunas (que valem `TRUE` ou `FALSE`) na base de dados de acordo com as expressões regulares abaixo.

```{r eval=FALSE}
negar_provimento <- 'negar?(do)? (o )?provimento|negou se (o )?provimento|recurso nao provido'
dar_provimento <- 'dar?(do)? (o )?provimento|deu se (o )?provimento|recurso provido'
em_parte <- 'em parte|parcial'
diligencia <- 'diligencia'
nao_conhecer <- 'conhec'
anular <- 'nul(a|o|i)'
```

**5** Faça uma tabela mostrando a quantidade de acórdãos em que foi dado provimento, negado provimento, etc. Considere somente os casos em que `tipo_recurso` é recurso voluntário.

## SABESP

Usando um _web crawler_ desenvolvido em R, fizemos o download da base de dados da SABESP. Quem tiver interesse nesses dados, acesse [aqui](https://github.com/jtrecenti/sabesp).

```{r eval=FALSE}
data(sabesp, package='abjutils')
```

**1** Descreva a base de dados.

**1** Crie uma tabela descritiva (média, desvio padrão, mediana, quartis, 
máximo, mínimo) por mês, mostrando os lugares separadamente.

**1** Construa uma tabela descritiva contendo a média, mediana, desvio padrão, primeiro e terceiro quartis em relação à pluviometria, agrupando por ano e por lugar.

**1** Comente sobre a crise hídrica em São Paulo com base em conhecimentos próprios e usando os dados da sabesp.

